{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the notebook"
      ],
      "metadata": {
        "id": "mvFX9xBAd3jF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the packages we need\n",
        "\n",
        "There are several libraries that have been created that we can use to make our job easier. We can import these libraries, so that we can take advantage of the functionalities they have, without developing the code ourselves.\n",
        "\n",
        "Importing these packages needs to be done at the **top** of the notebook, before we run any code.\n",
        "\n",
        "- [`pandas`](https://pandas.pydata.org/) \"is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool\"\n",
        "\n",
        "- [`sklearn`](https://scikit-learn.org/) is a library of tools for predictive and descriptive data analysis written in Python\n",
        "\n",
        "- [`matplotlib`](https://matplotlib.org/) is a library for creating visualizations\n",
        "\n",
        "- [`seaborn`](https://seaborn.pydata.org/) is a library for creating visualizations, built on top of `matplotlib`"
      ],
      "metadata": {
        "id": "TI6GgkYhd7nd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj_UNUriVPqC"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set()\n"
      ],
      "metadata": {
        "id": "6p_nhdGhE5v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Data"
      ],
      "metadata": {
        "id": "Zkk2sYK5iLRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## To Load our CSV file into a dataframe\n",
        "## First we need to provide access to our file\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ot6UGgSCiUyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load csv file into a dataframe \n",
        "\n",
        "data_path = \"/content/drive/MyDrive/FAI2223_Notebooks/data/spaceship_titanic_dataset.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "## Check file loaded\n",
        "df.head()"
      ],
      "metadata": {
        "id": "axw7sSsmiNaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## IF you have problems with Google Drive above, try this cell instead.\n",
        "## Un-comment the lines by removing the \"#\" character\n",
        "\n",
        "\n",
        "## Remove the \"#\" at the start of the lines below:\n",
        "\n",
        "#data_path = \"https://raw.githubusercontent.com/fpontejos/FAI_2223/main/data/spaceship_titanic_dataset.csv\"\n",
        "#df = pd.read_csv(data_path)\n",
        "\n",
        "#df.head()"
      ],
      "metadata": {
        "id": "XIqliwdQ9xWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset description\n",
        "\n",
        "Our dataset was taken from a Kaggle competition called Spaceship Titanic (Howard et al., 2022)<a name=\"cite1\"></a>[<sup>[1]</sup>](#note1)\n",
        "\n",
        "Given the details of the passengers on board a spaceship:\n",
        "\n",
        "1. create a predictive model for which passengers were transported to an alternate dimension. \n",
        "2. create a descriptive model about the passengers. \n",
        "\n",
        "- **PassengerId** - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
        "\n",
        "- **HomePlanet** - The planet the passenger departed from, typically their planet of permanent residence.\n",
        "\n",
        "- **CryoSleep** - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
        "\n",
        "- **Cabin** - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
        "\n",
        "- **Destination** - The planet the passenger will be debarking to.\n",
        "\n",
        "- **Age** - The age of the passenger.\n",
        "\n",
        "- **VIP** - Whether the passenger has paid for special VIP service during the voyage.\n",
        "\n",
        "- **RoomService**, **FoodCourt**, **ShoppingMall**, **Spa**, **VRDeck** - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
        "\n",
        "- **Name** - The first and last names of the passenger.\n",
        "\n",
        "- **Transported** - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict\n",
        "\n",
        "---\n",
        "<a name=\"cite-1\"></a>1. [^](#cite1) Howard, A., Chow, A., & Holbrook, R. (2022). Spaceship titanic. https://kaggle.com/competitions/spaceship-titanic"
      ],
      "metadata": {
        "id": "VHe_N-fPl5DA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring and Understanding the Data"
      ],
      "metadata": {
        "id": "WdwifcfqdzG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Define a function that plots multiple histograms\n",
        "\n",
        "def plot_multiple_histograms(data, feats, title=\"Numeric Variables' Histograms\"):\n",
        "\n",
        "    # Prepare figure. Create individual axes where each histogram will be placed\n",
        "    fig, axes = plt.subplots(2, ceil(len(feats) / 2), figsize=(20, 11))\n",
        "\n",
        "    # Plot data\n",
        "    # Iterate across axes objects and associate each histogram (hint: use the ax.hist() instead of plt.hist()):\n",
        "    for ax, feat in zip(axes.flatten(), feats): # Notice the zip() function and flatten() method\n",
        "      ax.hist(data[feat])\n",
        "      ax.set_title(feat)\n",
        "\n",
        "    # Layout\n",
        "    # Add a centered title to the figure:\n",
        "    plt.suptitle(title)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "## Define a function that plots multiple box plots\n",
        "\n",
        "def plot_multiple_boxplots(data, feats, title=\"Numeric Variables' Box Plots\"):\n",
        "\n",
        "    # Prepare figure. Create individual axes where each histogram will be placed\n",
        "    fig, axes = plt.subplots(2, ceil(len(feats) / 2), figsize=(20, 11))\n",
        "\n",
        "    # Plot data\n",
        "    # Iterate across axes objects and associate each histogram (hint: use the ax.hist() instead of plt.hist()):\n",
        "    for ax, feat in zip(axes.flatten(), feats): # Notice the zip() function and flatten() method\n",
        "      sns.boxplot(x=data[feat], ax=ax)\n",
        "      ax.set_title(feat)\n",
        "\n",
        "    # Layout\n",
        "    # Add a centered title to the figure:\n",
        "    plt.suptitle(title)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def plot_corrmatrix(df, feats, method=\"pearson\"):\n",
        "  # Prepare figure\n",
        "  fig = plt.figure(figsize=(10, 8))\n",
        "\n",
        "  # Obtain correlation matrix. Round the values to 2 decimal cases. Use the DataFrame corr() and round() method.\n",
        "  corr = np.round(df[feats].corr(method=method), decimals=2)\n",
        "\n",
        "  # Plot heatmap of the correlation matrix\n",
        "  sns.heatmap(data=corr, annot=True, cmap=sns.diverging_palette(220, 10, as_cmap=True), \n",
        "              vmin=-1, vmax=1, center=0, square=True, linewidths=.5)\n",
        "\n",
        "  # Layout\n",
        "  fig.subplots_adjust(top=0.95)\n",
        "  fig.suptitle(\"Correlation Matrix\", fontsize=20)\n",
        "\n",
        "  plt.show()\n",
        "  return \n",
        "\n",
        "## Define a function that plots multiple countplots\n",
        "\n",
        "def plot_categorical_frequencies(data, feats, \n",
        "                             title=\"Categorical Variables' Counts\"):\n",
        "  \n",
        "    # Prepare figure. Create individual axes where each histogram will be placed\n",
        "    fig, axes = plt.subplots(2, ceil(len(feats) / 2), figsize=(20, 11))\n",
        "\n",
        "    # Plot data\n",
        "    # Iterate across axes objects and associate each histogram (hint: use the ax.hist() instead of plt.hist()):\n",
        "    for ax, feat in zip(axes.flatten(), feats): \n",
        "        sns.countplot(x=df[feat].astype(object), ax=ax, color='#007acc')\n",
        "\n",
        "    # Layout\n",
        "    # Add a centered title to the figure:\n",
        "    plt.suptitle(title)\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return\n",
        "\n"
      ],
      "metadata": {
        "id": "2fTV7ShnCtBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insights from previous lab"
      ],
      "metadata": {
        "id": "7zaCGsGF_0dw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We have different kinds of variables"
      ],
      "metadata": {
        "id": "A54szeOlA5Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric_features = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
        "non_metric_features_all = [\"HomePlanet\", \"CryoSleep\", \"Cabin\", \"Destination\", \"VIP\"]\n",
        "non_metric_features = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\"]\n",
        "target_variable = \"Transported\""
      ],
      "metadata": {
        "id": "kGmEqvooAl-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We looked at the distributions of their values\n",
        "\n",
        "![Histograms](https://raw.githubusercontent.com/fpontejos/FAI_2223/main/images/histograms_original.png)"
      ],
      "metadata": {
        "id": "U_tBlBHAFRqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_multiple_histograms(df, metric_features)\n"
      ],
      "metadata": {
        "id": "IYL1lGM2Ets-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OBdUKafGkt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refresher on how to interpret boxplots and histograms:\n",
        "\n",
        "https://www.open.edu/openlearn/science-maths-technology/mathematics-statistics/interpreting-data-boxplots-and-tables/content-section-2.5\n",
        "\n",
        "https://statisticsbyjim.com/basics/histograms/\n"
      ],
      "metadata": {
        "id": "dhhtiOPvFHg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We have some outliers\n",
        "\n",
        "![Box Plots](https://raw.githubusercontent.com/fpontejos/FAI_2223/main/images/boxplots_original.png)"
      ],
      "metadata": {
        "id": "jYmdqIMkUlB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_multiple_boxplots(df, metric_features)\n"
      ],
      "metadata": {
        "id": "DTrM1JXOEuru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We have some missing values"
      ],
      "metadata": {
        "id": "K-D9BJCP_5oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Count of missing values\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "nmLCoRab_3c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Our values have different magnitudes"
      ],
      "metadata": {
        "id": "N9rXDDcB___x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n"
      ],
      "metadata": {
        "id": "1bAXVUn9AD4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some of our features are non-numeric "
      ],
      "metadata": {
        "id": "ssm3bLqLARwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[non_metric_features_all].head(3)"
      ],
      "metadata": {
        "id": "ukrPdCstAWxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df[non_metric_features_all].nunique()"
      ],
      "metadata": {
        "id": "5nXvPS2TLTsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s55ICfsNLj2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[metric_features].head(3)\n"
      ],
      "metadata": {
        "id": "IfN4eJZzChVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "En34wi_ILIlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How do we deal with these issues?\n",
        "\n"
      ],
      "metadata": {
        "id": "9QYKb9g_BALT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "W6Jks8TDjODq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Values\n",
        "\n",
        "What should we replace our missing values with?"
      ],
      "metadata": {
        "id": "owdmfQifBkLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Reminder of our missing values\n",
        "df[metric_features].isna().sum()"
      ],
      "metadata": {
        "id": "Pa8WMX5HFjj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## First we make a copy of our data. Why?\n",
        "\n",
        "df_original = df.copy()\n",
        "df_central = df.copy()\n"
      ],
      "metadata": {
        "id": "ikDFWM_pB8AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Measures of Central Tendency: Mean"
      ],
      "metadata": {
        "id": "y4Sx9NegBtEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_means = df_central[metric_features].mean()\n",
        "df_means"
      ],
      "metadata": {
        "id": "WTfuUy_lBj4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Measures of Central Tendency: Median"
      ],
      "metadata": {
        "id": "Vrk7NZtnBzXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_medians = df_central[metric_features].median()\n",
        "df_medians\n"
      ],
      "metadata": {
        "id": "VKifXtum4VlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Which one to use?"
      ],
      "metadata": {
        "id": "Zw-f7j-wFoPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_central['Spa'].hist(bins=10) ## Test other bin sizes\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "XaCIlfZaHOgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_central.fillna(df_medians, inplace=True)\n"
      ],
      "metadata": {
        "id": "bHN5akYv4VRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_central[metric_features].isna().sum()"
      ],
      "metadata": {
        "id": "uvGl4DlOGT1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What about the non-numeric values?"
      ],
      "metadata": {
        "id": "66gu-wjtI9z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_central[non_metric_features].isna().sum()\n"
      ],
      "metadata": {
        "id": "Oeqae2wnJFQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_categorical_frequencies(df, non_metric_features)\n"
      ],
      "metadata": {
        "id": "n7TM-3mNKHEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Count Plots](https://raw.githubusercontent.com/fpontejos/FAI_2223/main/images/value_counts_original.png)\n"
      ],
      "metadata": {
        "id": "0HqaGl9Lew3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_modes = df_central[non_metric_features].mode().loc[0]\n",
        "df_modes\n"
      ],
      "metadata": {
        "id": "XhNtkMzjJJxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_central.fillna(df_modes, inplace=True)\n"
      ],
      "metadata": {
        "id": "BtlxaAviJPAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_central[non_metric_features].isna().sum()\n"
      ],
      "metadata": {
        "id": "PsDqx5xEJa6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_categorical_frequencies(df_central, non_metric_features)\n"
      ],
      "metadata": {
        "id": "qaKqQYhDN80H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Once we are happy with our choices, copy it back to df\n",
        "df = df_central.copy()\n"
      ],
      "metadata": {
        "id": "D_DiQqlaJd3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Questions?"
      ],
      "metadata": {
        "id": "O3I2gfadJkrY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5UUTAwntJzPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treating Outliers"
      ],
      "metadata": {
        "id": "S_C4K3CCXgBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_outliers = df.copy()"
      ],
      "metadata": {
        "id": "lT4E16RpXjHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Uncomment line below to run the plotting code\n",
        "#plot_multiple_boxplots(df, metric_features)"
      ],
      "metadata": {
        "id": "RGi1yXFPXjAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Box Plots](https://raw.githubusercontent.com/fpontejos/FAI_2223/main/images/boxplots_original.png)"
      ],
      "metadata": {
        "id": "Mzzqs_eLeJ-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using Inter-Quartile Range (IQR)"
      ],
      "metadata": {
        "id": "dTg3mjGfa487"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers_iqr(df, feats, qa=0.25, qb=0.75):\n",
        "  df_ = df.copy()\n",
        "  q25 = df_[feats].quantile(.25)\n",
        "  q75 = df_[feats].quantile(.75)\n",
        "  iqr = (q75 - q25)\n",
        "\n",
        "  upper_lim = q75 + 1.5 * iqr\n",
        "  lower_lim = q25 - 1.5 * iqr\n",
        "\n",
        "  iqr_filters = []\n",
        "  for f in feats:\n",
        "      llim = lower_lim[f]\n",
        "      ulim = upper_lim[f]\n",
        "      iqr_filters.append(df[f].between(llim, ulim, inclusive='both'))\n",
        "\n",
        "  iqr_filters = pd.Series(np.all(iqr_filters, 0))\n",
        "  return df_[iqr_filters]\n",
        "\n"
      ],
      "metadata": {
        "id": "8Yf1OIsZYYat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DzRkZEiwaSHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_out_iqr = remove_outliers_iqr(df_outliers, metric_features)\n",
        "\n",
        "print('Percentage of data kept after removing outliers with IQR method:')\n",
        "print(np.round(df_out_iqr.shape[0] / df_outliers.shape[0], 4))\n"
      ],
      "metadata": {
        "id": "PXTN7sXoYYON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you think of this number?"
      ],
      "metadata": {
        "id": "j2rZaUb0aqJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using manual threshold"
      ],
      "metadata": {
        "id": "piVFv_aca9Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_multiple_boxplots(df_outliers, metric_features)\n"
      ],
      "metadata": {
        "id": "Fv-CnWdLbAjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manual_filters = (\n",
        "    (df_outliers['RoomService']<=8000)\n",
        "    &\n",
        "    (df_outliers['FoodCourt']<=20000)\n",
        "    &\n",
        "    (df_outliers['ShoppingMall']<=10000)\n",
        "    &\n",
        "    (df_outliers['Spa']<=15000)\n",
        "    &\n",
        "    (df_outliers['VRDeck']<=14000)\n",
        "\n",
        ")\n",
        "\n",
        "df_out_manual = df_outliers[manual_filters]\n"
      ],
      "metadata": {
        "id": "2qrCl6vias8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Percentage of data kept after removing outliers with manual method:')\n",
        "print(np.round(df_out_manual.shape[0] / df_outliers.shape[0], 4))\n"
      ],
      "metadata": {
        "id": "4iwFak3Hbn7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you think of this number?"
      ],
      "metadata": {
        "id": "3foxpUT9bvYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_out_manual.copy()"
      ],
      "metadata": {
        "id": "L-cMO1Odbx6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do we have to remove the rows?\n",
        "\n",
        "We will revisit this question later.\n"
      ],
      "metadata": {
        "id": "CjZ_J1Arb_-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Questions?"
      ],
      "metadata": {
        "id": "FgKA26eCcUbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Standardization\n",
        "\n",
        "Why do we need to do this?"
      ],
      "metadata": {
        "id": "azfEAwSiKg8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MinMaxScaler()\n",
        "\n",
        "Transforms values to be between [0,1]\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
      ],
      "metadata": {
        "id": "ljRWLlWXOUOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Again, make a copy first\n",
        "df_minmax = df.copy()\n"
      ],
      "metadata": {
        "id": "pM5hY1WJKirz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Initialize MinMaxScaler\n",
        "mm_scaler = MinMaxScaler()\n",
        "\n",
        "## Get the scaled values\n",
        "mm_scaled_feat = mm_scaler.fit_transform(df_minmax[metric_features])\n",
        "\n",
        "## Replace original metric_features values with mm_scaled_feat values\n",
        "df_minmax[metric_features] = mm_scaled_feat"
      ],
      "metadata": {
        "id": "_4vWb-z-MjpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "79suA0l0NMP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_minmax.describe().round(2)\n"
      ],
      "metadata": {
        "id": "mstLGW4XNeit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_multiple_histograms(df_minmax, metric_features)\n"
      ],
      "metadata": {
        "id": "oJkrzGSPPT9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### StandardScaler()\n",
        "\n",
        "AKA Z-Score Scaling\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
      ],
      "metadata": {
        "id": "46jI-WiEOW1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Again, make a copy first\n",
        "df_standard = df.copy()\n"
      ],
      "metadata": {
        "id": "VGLZCN29NpPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Initialize StandardScaler\n",
        "st_scaler = StandardScaler()\n",
        "\n",
        "## Get the scaled values\n",
        "st_scaled_feat = st_scaler.fit_transform(df_standard[metric_features])\n",
        "\n",
        "## Replace original metric_features values with mm_scaled_feat values\n",
        "df_standard[metric_features] = st_scaled_feat"
      ],
      "metadata": {
        "id": "6pUvuNhROaHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's look at the statistics\n",
        "## Rounded to two digits for easier viewing\n",
        "df_standard.describe().round(2)\n"
      ],
      "metadata": {
        "id": "fZJ7L84gOkVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_multiple_histograms(df_standard, metric_features)\n"
      ],
      "metadata": {
        "id": "zEkxnJp9Omhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_standard.copy()\n"
      ],
      "metadata": {
        "id": "XaEmqdm8PZHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WYC8m8Y5ShL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Selection"
      ],
      "metadata": {
        "id": "eQsV0EK2lEyh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Redundancy\n",
        "\n",
        "We've already seen our correlation matrix. This can help us see which variables are highly correlated to each other, which we can then choose to remove."
      ],
      "metadata": {
        "id": "o_ZVvgH6njBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_corrmatrix(df, metric_features, method=\"pearson\")"
      ],
      "metadata": {
        "id": "35-X8F-RnwrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Relevancy\n",
        "\n",
        "We select only the variables that are relevant to the task. For example, if the task is to create a demographic segmentation, then we only keep demographic variables. For now, since we don't have a specific task, we consider all variables to be relevant.\n"
      ],
      "metadata": {
        "id": "HrJXBqLlleLg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5xb_LzGNT8TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Questions?"
      ],
      "metadata": {
        "id": "A7noGwXDcYmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wrap up\n",
        "\n",
        "#### Redo data exploration\n",
        "\n",
        "Check if the data looks the way you expect it to. \n",
        "\n",
        "- Have you missed some outliers? \n",
        "- Are there still missing values?\n",
        "- Is the data normalized?\n",
        "\n",
        "This is an iterative process. It is likely you will change your preprocessing steps frequently throughout your group work."
      ],
      "metadata": {
        "id": "roRDCWy3dGF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next lab\n",
        "\n",
        "KMeans Clustering\n",
        "\n",
        "https://www.youtube.com/watch?v=5I3Ei69I40s\n",
        "\n",
        "\n",
        "Hierarchical Clustering\n",
        "\n",
        "https://dashee87.github.io/images/hierarch.gif"
      ],
      "metadata": {
        "id": "rQF6RvQuc8f3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r27ESEfsk9sM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}